{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Seoz5Qy06exj",
        "outputId": "e16956eb-2be3-4a9f-aeaf-33f94095bac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.116.1)\n",
            "Collecting uvicorn==0.13.1\n",
            "  Downloading uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following yanked versions: 0.17.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement uvicorn==0.13.1 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 0.0.7, 0.0.8, 0.0.9, 0.0.10, 0.0.11, 0.0.12, 0.0.13, 0.0.14, 0.0.15, 0.1.0, 0.1.1, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.2.6, 0.2.7, 0.2.8, 0.2.9, 0.2.10, 0.2.11, 0.2.12, 0.2.13, 0.2.14, 0.2.15, 0.2.16, 0.2.17, 0.2.18, 0.2.19, 0.2.20, 0.2.21, 0.2.22, 0.3.0, 0.3.1, 0.3.2, 0.3.3, 0.3.4, 0.3.5, 0.3.6, 0.3.7, 0.3.8, 0.3.9, 0.3.10, 0.3.11, 0.3.12, 0.3.13, 0.3.14, 0.3.15, 0.3.16, 0.3.17, 0.3.18, 0.3.19, 0.3.20, 0.3.21, 0.3.22, 0.3.23, 0.3.24, 0.3.25, 0.3.26, 0.3.27, 0.3.28, 0.3.29, 0.3.30, 0.3.31, 0.3.32, 0.4.0, 0.4.1, 0.4.2, 0.4.3, 0.4.4, 0.4.5, 0.4.6, 0.5.0, 0.5.1, 0.5.2, 0.6.0, 0.6.1, 0.7.0b1, 0.7.0b2, 0.7.0, 0.7.1, 0.7.2, 0.7.3, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.8.4, 0.8.5, 0.8.6, 0.9.0, 0.9.1, 0.10.0, 0.10.1, 0.10.2, 0.10.3, 0.10.4, 0.10.5, 0.10.6, 0.10.7, 0.10.8, 0.10.9, 0.11.0, 0.11.1, 0.11.2, 0.11.3, 0.11.4, 0.11.5, 0.11.6, 0.11.7, 0.11.8, 0.12.0, 0.12.1, 0.12.2, 0.12.3, 0.13.0, 0.13.1, 0.13.2, 0.13.3, 0.13.4, 0.14.0, 0.15.0, 0.16.0, 0.17.0.post1, 0.17.1, 0.17.2, 0.17.3, 0.17.4, 0.17.5, 0.17.6, 0.18.0, 0.18.1, 0.18.2, 0.18.3, 0.19.0, 0.20.0, 0.21.0, 0.21.1, 0.22.0, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.0.post1, 0.25.0, 0.26.0, 0.27.0, 0.27.0.post1, 0.27.1, 0.28.0, 0.28.1, 0.29.0, 0.30.0, 0.30.1, 0.30.2, 0.30.3, 0.30.4, 0.30.5, 0.30.6, 0.31.0, 0.31.1, 0.32.0, 0.32.1, 0.33.0, 0.34.0, 0.34.1, 0.34.2, 0.34.3, 0.35.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for uvicorn==0.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install fastapi uvicorn==0.13.1 colabcode==0.1.1 pyngrok==4.1.1 transformers torch reportlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob5_ZGCk6jT7",
        "outputId": "0f008ae9-9fcf-4769-80c0-071a0563e4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.116.1)\n",
            "Requirement already satisfied: uvicorn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.35.0)\n",
            "Collecting colabcode\n",
            "  Downloading colabcode-0.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.54.0)\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.7.1)\n",
            "Requirement already satisfied: reportlab in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.4.2)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fastapi) (0.47.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from fastapi) (4.14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: click>=7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from uvicorn) (0.16.0)\n",
            "Collecting nest-asyncio==1.4.3 (from colabcode)\n",
            "  Downloading nest_asyncio-1.4.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting uvicorn\n",
            "  Using cached uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of colabcode to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting colabcode\n",
            "  Downloading colabcode-0.2.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting uvicorn\n",
            "  Using cached uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting colabcode\n",
            "  Downloading colabcode-0.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting uvicorn\n",
            "  Using cached uvicorn-0.13.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting colabcode\n",
            "  Downloading colabcode-0.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from reportlab) (3.4.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->transformers) (2025.7.14)\n",
            "Downloading colabcode-0.1.1-py3-none-any.whl (4.6 kB)\n",
            "Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyngrok, colabcode\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [colabcode]\n",
            "\u001b[1A\u001b[2KSuccessfully installed colabcode-0.1.1 pyngrok-7.2.12\n"
          ]
        }
      ],
      "source": [
        "!pip3 install fastapi uvicorn colabcode pyngrok transformers torch reportlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5d8smv46yfg",
        "outputId": "c1f5d812-9e7e-4c6b-b8bc-dfb6958a16f0"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMounting Google Drive...\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted.\")\n",
        "else:\n",
        "    print(\"Google Drive already mounted.\")\n",
        "\n",
        "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/llm-cv-parser-v2\"\n",
        "FINAL_MODEL_DIR = f\"{DRIVE_OUTPUT_DIR}/final_merged_model_v2\"\n",
        "os.makedirs(FINAL_MODEL_DIR, exist_ok=True)\n",
        "print(f\"Ensured model directory exists: {FINAL_MODEL_DIR}\")\n",
        "\n",
        "print(\"Installing dependencies...\")\n",
        "!pip3 install -q -U transformers datasets accelerate peft bitsandbytes trl fastapi uvicorn pyngrok reportlab textblob groq python-multipart simplejson\n",
        "\n",
        "print(\"Dependencies installed.\")\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    ngrok_auth_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "    if not ngrok_auth_token:\n",
        "        raise ValueError(\"NGROK_AUTH_TOKEN secret not found or empty.\")\n",
        "    os.environ[\"NGROK_AUTH_TOKEN\"] = ngrok_auth_token\n",
        "    print(\"Ngrok authtoken confirmed from Colab secrets.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error setting Ngrok authtoken: {e}\")\n",
        "    print(\"Please ensure NGROK_AUTH_TOKEN is set in Colab Secrets and enabled for this notebook.\")\n",
        "    # You cannot proceed without the token, so raising an error is appropriate\n",
        "    raise SystemExit(\"Ngrok authentication failed. Exiting.\")\n",
        "\n",
        "try:\n",
        "    groq_api_key = userdata.get('GROQ_API_KEY')\n",
        "    if not groq_api_key:\n",
        "        raise ValueError(\"GROQ_API_KEY secret not found or empty.\")\n",
        "    os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
        "    print(\"GROQ_API_KEY confirmed from Colab secrets.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error setting GROQ_API_KEY: {e}\")\n",
        "    print(\"Please ensure GROQ_API_KEY is set in Colab Secrets and enabled for this notebook.\")\n",
        "    raise SystemExit(\"Groq API key not available. Exiting.\")\n",
        "\n",
        "print(\"All initial setup complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJETyk2f7aZ-",
        "outputId": "f3dafd4b-4a08-428e-d8eb-8ab7aae7ce60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All libraries are imported\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import torch\n",
        "import traceback # Import traceback for better error logging\n",
        "\n",
        "from fastapi import FastAPI, Form, Response\n",
        "from fastapi.responses import JSONResponse, HTMLResponse, StreamingResponse\n",
        "\n",
        "# These imports are only needed if you are running in Colab and getting secrets directly\n",
        "# In a production Docker/VM setup, you'd usually pass these as environment variables.\n",
        "# from google.colab import userdata # Not needed here as secrets are loaded to os.environ in Cell 1\n",
        "from groq import Groq\n",
        "\n",
        "# ReportLab imports for PDF generation\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.platypus import Paragraph\n",
        "from reportlab.lib.units import inch\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Hugging Face imports for LLM\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "print(\"All libraries are imported\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyF3c9Q87oim",
        "outputId": "07c5057f-8e54-42ce-b989-599693d059d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting cv_api.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile cv_api.py\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import io\n",
        "import torch\n",
        "import traceback # Import traceback for better error logging\n",
        "import base64 # For base64 encoding PDF\n",
        "\n",
        "from fastapi import FastAPI, Form, Response\n",
        "from fastapi.responses import JSONResponse, HTMLResponse, StreamingResponse\n",
        "\n",
        "# Removed Groq import\n",
        "# from groq import Groq\n",
        "\n",
        "# ReportLab imports for PDF generation\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.platypus import Paragraph\n",
        "from reportlab.lib.units import inch\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Hugging Face imports for LLM\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Define the FastAPI app\n",
        "app = FastAPI(\n",
        "    title=\"ATS-Friendly CV Generator API\",\n",
        "    description=\"API to generate structured CV data, Markdown, and PDF from unstructured text using a fine-tuned LLM.\", # Removed Groq mention\n",
        "    version=\"2.5.0\"\n",
        ")\n",
        "\n",
        "# Removed Groq client initialization\n",
        "# groq_client = None\n",
        "\n",
        "# Load the local fine-tuned model and tokenizer\n",
        "MODEL_PATH = \"/content/drive/MyDrive/llm-cv-parser-v2/final_merged_model_v2\"\n",
        "\n",
        "model = None\n",
        "tokenizer = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def load_model():\n",
        "    global model, tokenizer\n",
        "    try:\n",
        "        print(f\"Attempting to load model from: {MODEL_PATH}\")\n",
        "        # local_files_only=True ensures it doesn't try to download from Hugging Face Hub\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            MODEL_PATH,\n",
        "            torch_dtype=torch.float16,\n",
        "            device_map=\"auto\",\n",
        "            local_files_only=True # Important\n",
        "        )\n",
        "        model.eval() # Set to evaluation mode\n",
        "        print(\"Local fine-tuned model and tokenizer loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading local model during startup: {e}\")\n",
        "        # Ensure model and tokenizer are None if loading fails\n",
        "        model = None\n",
        "        tokenizer = None\n",
        "        # Raise an exception to prevent the app from starting if model isn't loaded\n",
        "        raise RuntimeError(f\"Model loading failed: {e}\")\n",
        "\n",
        "\n",
        "def build_prompt(cv_text: str) -> str:\n",
        "    return f\"\"\"<|system|>You are an expert resume parser that extracts information from CV text and returns it as JSON.</s>\n",
        "<|user|>{cv_text}</s>\n",
        "<|assistant|>\"\"\"\n",
        "\n",
        "def generate_llm_response(cv_text: str, max_new_tokens: int = 8000) -> str:\n",
        "    \"\"\"Generates initial raw output from the local fine-tuned model.\"\"\"\n",
        "    if model is None or tokenizer is None:\n",
        "        raise RuntimeError(\"LLM model or tokenizer not loaded. Cannot generate response.\")\n",
        "\n",
        "    prompt = build_prompt(cv_text)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(model.device) # Add truncation\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.7,\n",
        "            do_sample=False,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Decode only the generated part after the prompt\n",
        "    # Find the start of the assistant's response to avoid re-decoding the prompt\n",
        "    decoded_full_output = tokenizer.decode(output[0], skip_special_tokens=False) # Keep special tokens for split\n",
        "    assistant_prefix = \"<|assistant|>\"\n",
        "    if assistant_prefix in decoded_full_output:\n",
        "        response_text = decoded_full_output.split(assistant_prefix)[-1].strip()\n",
        "    else:\n",
        "        # Fallback if assistant prefix isn't found (shouldn't happen with proper prompt)\n",
        "        response_text = tokenizer.decode(output[0][inputs.input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
        "\n",
        "    # Clean up any residual special tokens that might be left if skip_special_tokens was false\n",
        "    response_text = response_text.replace(\"</s>\", \"\").replace(\"<unk>\", \"\").strip()\n",
        "\n",
        "    return response_text\n",
        "\n",
        "def extract_and_fix_json(raw_text):\n",
        "    \"\"\"\n",
        "    Specifically extracts JSON from a string potentially wrapped in 'raw_output': '...'\n",
        "    and applies specific fixes. This is the version you provided for explicit use.\n",
        "    \"\"\"\n",
        "    print(\"Attempting JSON extraction and basic fixes (your provided function)...\")\n",
        "    match = re.search(r\"'raw_output':\\s*'(.*?)'\\s*$\", raw_text.strip(), re.DOTALL)\n",
        "    if not match:\n",
        "        print(\"Could not find 'raw_output' wrapper. Treating input as direct JSON string.\")\n",
        "        json_str = raw_text.strip()\n",
        "    else:\n",
        "        json_str = match.group(1)\n",
        "        print(\"Found and extracted content from 'raw_output' wrapper.\")\n",
        "\n",
        "    # Apply fixes from your provided function\n",
        "    json_str = re.sub(r'(\"phone\":\\s*\"\\+94\\s*\\d{2}\\s*\\d{3}\\s*\\d{4})(,)\\s*\"email\":', r'\\1\", \"email\":', json_str)\n",
        "    json_str = re.sub(r',\\s*([\\]}])', r'\\1', json_str)\n",
        "\n",
        "    braces_diff = json_str.count('{') - json_str.count('}')\n",
        "    brackets_diff = json_str.count('[') - json_str.count(']')\n",
        "\n",
        "    json_str += '}' * braces_diff\n",
        "    json_str += ']' * brackets_diff\n",
        "\n",
        "    try:\n",
        "        parsed_json = json.loads(json_str)\n",
        "        print(\"Successfully extracted and parsed JSON after basic fixes.\")\n",
        "        return parsed_json\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON decode error after basic fixes: {e}\")\n",
        "        raise ValueError(f\"Could not parse JSON after basic fixes: {e}\") # Raise ValueError to indicate failure\n",
        "\n",
        "\n",
        "# Consolidated the robust parsing logic into one main function.\n",
        "# This function will be the only custom parser.\n",
        "def convert_raw_output_to_json(raw_output_from_llm: str) -> dict:\n",
        "    \"\"\"\n",
        "    Convert raw LLM output to valid JSON format using custom extraction and fixing.\n",
        "    This is the primary JSON parsing pipeline without external API calls.\n",
        "    \"\"\"\n",
        "    print(\"Converting raw output to JSON using custom robust method...\")\n",
        "    print(f\"--- Raw Output (first 500 chars) ---\")\n",
        "    print(raw_output_from_llm[:500] + \"...\" if len(raw_output_from_llm) > 500 else raw_output_from_llm)\n",
        "\n",
        "    # First attempt: Try to parse directly (if it's already perfect JSON)\n",
        "    try:\n",
        "        parsed_json = json.loads(raw_output_from_llm)\n",
        "        print(\"Raw output was already valid JSON, no custom fixing needed.\")\n",
        "        return parsed_json\n",
        "    except json.JSONDecodeError:\n",
        "        pass # If direct parsing fails, proceed to custom extraction and fixing\n",
        "\n",
        "    # Second attempt: Use the custom extract_and_fix_json function\n",
        "    try:\n",
        "        parsed_json = extract_and_fix_json(raw_output_from_llm) # Calling your specified fixer\n",
        "        print(f\"--- Converted JSON (formatted) ---\")\n",
        "        print(json.dumps(parsed_json, indent=2)[:1000] + \"...\" if len(json.dumps(parsed_json, indent=2)) > 1000 else json.dumps(parsed_json, indent=2))\n",
        "        return parsed_json\n",
        "    except (ValueError, json.JSONDecodeError) as e:\n",
        "        print(f\"All custom JSON parsing attempts failed: {e}. No further fallback.\")\n",
        "        raise json.JSONDecodeError(f\"All custom parsing attempts failed: {e}\", raw_output_from_llm, 0)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during custom conversion: {e}\")\n",
        "        raise json.JSONDecodeError(f\"Unexpected error during custom parsing: {e}\", raw_output_from_llm, 0)\n",
        "\n",
        "# Removed repair_json_with_llm function as it depended on Groq\n",
        "# def repair_json_with_llm(malformed_json_str: str, schema_str: str = None) -> str:\n",
        "#     # ... (old code) ...\n",
        "\n",
        "def flatten_cv_json(cv_json: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Standardizes the JSON structure, moving potentially mis-nested fields\n",
        "    and ensuring all expected top-level keys exist.\n",
        "    \"\"\"\n",
        "    if 'skills' in cv_json and isinstance(cv_json['skills'], list):\n",
        "        if cv_json['skills'] and isinstance(cv_json['skills'][0], str):\n",
        "            cv_json['skills'] = [{\"category\": \"Technical Skills\", \"items\": cv_json['skills']}]\n",
        "    if 'tools' in cv_json and isinstance(cv_json['tools'], list):\n",
        "        if 'skills' not in cv_json: cv_json['skills'] = []\n",
        "        cv_json['skills'].append({\"category\": \"Tools & Technologies\", \"items\": cv_json['tools']})\n",
        "        del cv_json['tools']\n",
        "    if 'experience' in cv_json and isinstance(cv_json['experience'], list) and len(cv_json['experience']) > 0:\n",
        "        exp0 = cv_json['experience'][0]\n",
        "        for key in ['projects', 'education', 'volunteering_and_leadership', 'references']:\n",
        "            if key in exp0 and key not in cv_json:\n",
        "                cv_json[key] = exp0[key]\n",
        "                if key in exp0: del exp0[key]\n",
        "    for key in ['name', 'job_title', 'contact', 'profile_summary', 'skills', 'experience', 'projects', 'education', 'volunteering_and_leadership', 'references']:\n",
        "        if key not in cv_json:\n",
        "            if key in ['name', 'job_title', 'profile_summary']: cv_json[key] = \"\"\n",
        "            elif key == 'contact': cv_json[key] = {}\n",
        "            else: cv_json[key] = []\n",
        "    if 'references' in cv_json and isinstance(cv_json['references'], list):\n",
        "        for i, ref in enumerate(cv_json['references']):\n",
        "            # Ensure contact is a dictionary before trying to access keys\n",
        "            if 'contact' in ref and isinstance(ref['contact'], dict):\n",
        "                if 'phone' in ref['contact']: cv_json['references'][i]['phone'] = ref['contact']['phone']\n",
        "                if 'email' in ref['contact']: cv_json['references'][i]['email'] = ref['contact']['email']\n",
        "                del cv_json['references'][i]['contact']\n",
        "            # If phone or email are directly at top-level of reference, move them to the new structure if not already there\n",
        "            if 'phone' in ref and 'phone' not in cv_json['references'][i]: cv_json['references'][i]['phone'] = ref['phone']\n",
        "            if 'email' in ref and 'email' not in cv_json['references'][i]: cv_json['references'][i]['email'] = ref['email']\n",
        "\n",
        "    return cv_json\n",
        "\n",
        "def add_word_spacing(text: str) -> str:\n",
        "    # Use raw strings for regex patterns\n",
        "    text = re.sub(r',([^\\s])', r', \\1', text)\n",
        "    text = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text)\n",
        "    text = re.sub(r'\\s{2,}', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "def draw_justified_paragraph(c: canvas.Canvas, text: str, x: float, y: float, width: float, font_name: str, font_size: float, line_height: float, indent: float = 0, extra_word_space: float = 0) -> float:\n",
        "    from reportlab.pdfbase.pdfmetrics import stringWidth # Needs to be imported here if not global\n",
        "    styles = getSampleStyleSheet()\n",
        "    style = styles['Normal']\n",
        "    style.fontName = font_name\n",
        "    style.fontSize = font_size\n",
        "    style.leading = line_height\n",
        "    style.alignment = 4 # TA_JUSTIFY\n",
        "    style.firstLineIndent = indent\n",
        "    if not text.strip(): return y - line_height\n",
        "    words = text.split()\n",
        "    if not words: return y - line_height # Handle empty words list\n",
        "    lines = []; current_line = []; current_width = 0; space_width = stringWidth(' ', font_name, font_size)\n",
        "    for word in words:\n",
        "        word_len = stringWidth(word, font_name, font_size);\n",
        "        test_width = current_width + word_len + (space_width if current_line else 0) # Only add space if not first word\n",
        "        if test_width > width and current_line: # If adding this word exceeds width and line is not empty\n",
        "            lines.append(' '.join(current_line));\n",
        "            current_line = [word];\n",
        "            current_width = word_len;\n",
        "        else:\n",
        "            current_line.append(word);\n",
        "            current_width += word_len + space_width; # Add space after word\n",
        "    if current_line: lines.append(' '.join(current_line)) # Add last line\n",
        "\n",
        "    for i, line_text in enumerate(lines):\n",
        "        current_draw_x = x + (indent if i == 0 else 0) # Apply first line indent\n",
        "        line_word_count = len(line_text.split())\n",
        "\n",
        "        if i == len(lines) - 1 or line_word_count == 1: # Last line or single word line, left align\n",
        "            c.drawString(current_draw_x, y, line_text)\n",
        "        else: # Justify line\n",
        "            text_width = stringWidth(line_text, font_name, font_size);\n",
        "            if line_word_count > 1:\n",
        "                # Calculate extra space needed for justification\n",
        "                extra_space_per_gap = (width - text_width) / (line_word_count - 1)\n",
        "            else:\n",
        "                extra_space_per_gap = 0 # Should not happen for mult-word lines\n",
        "\n",
        "            word_parts = line_text.split(' ')\n",
        "            for j, word in enumerate(word_parts):\n",
        "                c.drawString(current_draw_x, y, word)\n",
        "                current_draw_x += stringWidth(word, font_name, font_size)\n",
        "                if j < line_word_count - 1: # Add space after word, except for the last word\n",
        "                    current_draw_x += (space_width + extra_space_per_gap + extra_word_space)\n",
        "        y -= line_height\n",
        "    return y\n",
        "\n",
        "\n",
        "def create_styled_cv_from_json(data: dict, file_buffer: io.BytesIO) -> io.BytesIO:\n",
        "    c = canvas.Canvas(file_buffer, pagesize=A4); width, height = A4\n",
        "    left_margin = 0.5 * inch; right_margin = width - 0.5 * inch; top_margin = height - 0.5 * inch; bottom_margin = 0.5 * inch; content_width = width - 1 * inch\n",
        "    y_pos = top_margin; x_pos = left_margin; page_count = 1\n",
        "\n",
        "    # Header Section\n",
        "    name = data.get('name', 'Your Name'); job_title = data.get('job_title', 'Job Title'); contact_info = data.get('contact', {})\n",
        "    email = contact_info.get('email', ''); phone = contact_info.get('phone', ''); location = contact_info.get('location', ''); linkedin = contact_info.get('linkedin', ''); github = contact_info.get('github', ''); website = contact_info.get('website', '')\n",
        "    c.setFont('Helvetica-Bold', 18); c.drawCentredString(width / 2.0, y_pos, name); y_pos -= 18\n",
        "    if job_title: c.setFont('Helvetica', 12); c.drawCentredString(width / 2.0, y_pos, job_title); y_pos -= 15\n",
        "    contact_parts = [part for part in [email, phone, location, linkedin, github, website] if part]; contact_line = \" | \".join(contact_parts)\n",
        "    if contact_line: c.setFont('Helvetica', 10); c.drawCentredString(width / 2.0, y_pos, contact_line); y_pos -= 15\n",
        "    max_text_width = max(c.stringWidth(name, 'Helvetica-Bold', 18), c.stringWidth(job_title, 'Helvetica', 12), c.stringWidth(contact_line, 'Helvetica', 10) if contact_line else 0)\n",
        "    line_margin = 20; line_x_start = (width - max_text_width) / 2 - line_margin; line_x_end = (width + max_text_width) / 2 + line_margin; line_y = y_pos + 5; c.setLineWidth(0.5); c.line(line_x_start, line_y, line_x_end, line_y); y_pos = line_y - 15\n",
        "\n",
        "    # Profile Summary\n",
        "    summary_text = data.get('profile_summary', ''); c.setFont('Helvetica', 10)\n",
        "    # Check if TextBlob is available before using it\n",
        "    if 'TextBlob' in globals() and TextBlob is not None:\n",
        "        try:\n",
        "            summary_text_corrected = str(TextBlob(summary_text).correct())\n",
        "        except Exception as e:\n",
        "            print(f\"TextBlob correction failed for summary: {e}. Using original text.\")\n",
        "            summary_text_corrected = summary_text\n",
        "    else: summary_text_corrected = summary_text\n",
        "    summary_text_corrected = add_word_spacing(summary_text_corrected); y_pos = draw_justified_paragraph(c, summary_text_corrected, x_pos, y_pos, content_width, 'Helvetica', 10, 12, indent=0); y_pos -= 5\n",
        "\n",
        "    # Page break check\n",
        "    if y_pos < bottom_margin + 50:\n",
        "        c.showPage()\n",
        "        y_pos = top_margin\n",
        "        page_count += 1\n",
        "        if page_count > 2: # Limit to 2 pages\n",
        "            c.save()\n",
        "            return file_buffer\n",
        "\n",
        "    # Skills Section\n",
        "    skills = data.get('skills', []);\n",
        "    if skills:\n",
        "        c.setFont('Helvetica-Bold', 12); c.drawString(x_pos, y_pos, 'SKILLS'); y_pos -= 20\n",
        "        for skill_cat in skills:\n",
        "            c.setFont('Helvetica-Bold', 11); c.drawString(x_pos, y_pos, skill_cat.get('category', '')); y_pos -= 15\n",
        "            c.setFont('Helvetica', 10); skills_list = skill_cat.get('items', []); skills_text = \", \".join(skills_list);\n",
        "            # Simple text wrapping for skills list\n",
        "            current_line = \"\"\n",
        "            for i, word in enumerate(skills_text.split(', ')): # Split by ', ' to keep phrases intact\n",
        "                if i > 0: test_line = current_line + \", \" + word # Add comma for subsequent items\n",
        "                else: test_line = current_line + word\n",
        "                if c.stringWidth(test_line, 'Helvetica', 10) <= content_width:\n",
        "                    current_line = test_line\n",
        "                else:\n",
        "                    if current_line: c.drawString(x_pos, y_pos, current_line.strip()); y_pos -= 12\n",
        "                    current_line = word # Start new line with the current word\n",
        "            if current_line: c.drawString(x_pos, y_pos, current_line.strip()); y_pos -= 15\n",
        "    y_pos -= 10;\n",
        "\n",
        "    # Page break check\n",
        "    if y_pos < bottom_margin + 50:\n",
        "        c.showPage()\n",
        "        y_pos = top_margin\n",
        "        page_count += 1\n",
        "        if page_count > 2:\n",
        "            c.save()\n",
        "            return file_buffer\n",
        "\n",
        "    # Work Experience Section\n",
        "    experience = data.get('experience', []);\n",
        "    if experience:\n",
        "        c.setFont('Helvetica-Bold', 12); c.drawString(x_pos, y_pos, 'WORK EXPERIENCE'); y_pos -= 20\n",
        "        for job in experience:\n",
        "            c.setFont('Helvetica-Bold', 11); title_line = f\"{job.get('title', '')}, {job.get('company', '')}\"; c.drawString(x_pos, y_pos, title_line); y_pos -= 15\n",
        "            c.setFont('Helvetica', 10); c.drawString(x_pos, y_pos, job.get('duration', '')); y_pos -= 15\n",
        "            responsibilities = job.get('responsibilities', []);\n",
        "            for resp in responsibilities:\n",
        "                resp_text = resp.strip();\n",
        "                if 'TextBlob' in globals() and TextBlob is not None:\n",
        "                    try:\n",
        "                        resp_text = str(TextBlob(resp_text).correct())\n",
        "                    except Exception as e:\n",
        "                        print(f\"TextBlob correction failed for responsibility: {e}. Using original text.\")\n",
        "                        pass # Continue with original text if correction fails\n",
        "                resp_text = re.sub(r'\\s*\\([^)]*\\)', '', resp_text).strip(); # Remove text in parentheses\n",
        "                if len(resp_text) > 150: resp_text = resp_text[:147] + \"...\" # Truncate long responsibilities\n",
        "                y_pos_after_draw = draw_justified_paragraph(c, \"• \" + resp_text, x_pos, y_pos, content_width, 'Helvetica', 10, 12, indent=0)\n",
        "                y_pos = y_pos_after_draw # Update y_pos based on paragraph drawing\n",
        "                if y_pos < bottom_margin + 30: # Check for page break after each responsibility\n",
        "                    c.showPage()\n",
        "                    y_pos = top_margin\n",
        "                    page_count += 1\n",
        "                if page_count > 2:\n",
        "                    c.save()\n",
        "                    return file_buffer\n",
        "            y_pos -= 15;\n",
        "\n",
        "    # Page break check\n",
        "    if y_pos < bottom_margin + 50:\n",
        "        c.showPage()\n",
        "        y_pos = top_margin\n",
        "        page_count += 1\n",
        "        if page_count > 2:\n",
        "            c.save()\n",
        "            return file_buffer\n",
        "\n",
        "    # Projects Section\n",
        "    projects = data.get('projects', []);\n",
        "    if projects and page_count <= 2:\n",
        "        c.setFont('Helvetica-Bold', 12); c.drawString(x_pos, y_pos, 'PROJECTS'); y_pos -= 20;\n",
        "        for proj in projects:\n",
        "            c.setFont('Helvetica-Bold', 10); project_title = proj.get('name', '');\n",
        "            if proj.get('role'): project_title += f\" - {proj.get('role', '')}\";\n",
        "            c.drawString(x_pos, y_pos, project_title); y_pos -= 12;\n",
        "\n",
        "            c.setFont('Helvetica', 10); desc = proj.get('description', '');\n",
        "            if 'TextBlob' in globals() and TextBlob is not None:\n",
        "                try:\n",
        "                    desc = str(TextBlob(desc).correct());\n",
        "                except Exception as e:\n",
        "                    print(f\"TextBlob correction failed for project description: {e}. Using original text.\")\n",
        "                    pass\n",
        "            desc = add_word_spacing(desc); desc = desc.replace('\\n', ' ').strip();\n",
        "            y_pos = draw_justified_paragraph(c, desc, x_pos, y_pos, content_width, 'Helvetica', 10, 12, indent=0, extra_word_space=2);\n",
        "\n",
        "            if proj.get('technologies'):\n",
        "                tech_line = \"Technologies: \" + \", \".join(proj.get('technologies', [])); c.setFont('Helvetica', 9);\n",
        "                # Simple text wrapping for tech list\n",
        "                current_line = \"\"\n",
        "                for i, word in enumerate(tech_line.split(', ')):\n",
        "                    if i > 0: test_line = current_line + \", \" + word\n",
        "                    else: test_line = current_line + word\n",
        "                    if c.stringWidth(test_line, 'Helvetica', 9) <= content_width:\n",
        "                        current_line = test_line\n",
        "                    else:\n",
        "                        if current_line: c.drawString(x_pos, y_pos, current_line.strip()); y_pos -= 10\n",
        "                        current_line = word\n",
        "                if current_line: c.drawString(x_pos, y_pos, current_line.strip()); y_pos -= 10\n",
        "            y_pos -= 15;\n",
        "            if y_pos < bottom_margin + 30:\n",
        "                c.showPage()\n",
        "                y_pos = top_margin\n",
        "                page_count += 1\n",
        "            if page_count > 2:\n",
        "                c.save()\n",
        "                return file_buffer;\n",
        "\n",
        "    # Education Section\n",
        "    education = data.get('education', []);\n",
        "    if education:\n",
        "        c.setFont('Helvetica-Bold', 12); c.drawString(x_pos, y_pos, 'EDUCATION'); y_pos -= 15;\n",
        "        for edu in education:\n",
        "            c.setFont('Helvetica-Bold', 10); degree = edu.get('degree', ''); c.drawString(x_pos, y_pos, degree); y_pos -= 10;\n",
        "            c.drawString(x_pos, y_pos, edu.get('institution', '')); y_pos -= 10; c.setFont('Helvetica', 10);\n",
        "            if edu.get('details'): c.drawString(x_pos, y_pos, edu.get('details', '')); y_pos -= 10;\n",
        "            if edu.get('duration'): c.drawString(x_pos, y_pos, edu.get('duration', '')); y_pos -= 10;\n",
        "            y_pos -= 10;\n",
        "\n",
        "    # Volunteering & Leadership Section\n",
        "    volunteering = data.get('volunteering_and_leadership', []);\n",
        "    if volunteering and page_count <= 2:\n",
        "        if y_pos < bottom_margin + 50:\n",
        "            c.showPage()\n",
        "            y_pos = top_margin\n",
        "            page_count += 1\n",
        "        if page_count > 2:\n",
        "            c.save()\n",
        "            return file_buffer;\n",
        "        c.setFont('Helvetica-Bold', 12); c.drawString(x_pos, y_pos, 'VOLUNTEERING & LEADERSHIP'); y_pos -= 15;\n",
        "        c.setFont('Helvetica', 10);\n",
        "        for vol in volunteering[:5]: # Limit to first 5 for conciseness in PDF\n",
        "            vol_text = vol;\n",
        "            if len(vol_text) > 100: vol_text = vol_text[:97] + \"...\"; # Truncate\n",
        "            y_pos_after_draw = draw_justified_paragraph(c, \"• \" + vol_text, x_pos, y_pos, content_width, 'Helvetica', 10, 12, indent=0)\n",
        "            y_pos = y_pos_after_draw\n",
        "        y_pos -= 10;\n",
        "\n",
        "    # References Section\n",
        "    references = data.get('references', []);\n",
        "    if references and page_count <= 2 and y_pos > bottom_margin + 50:\n",
        "        c.setFont('Helvetica-Bold', 12); c.drawString(x_pos, y_pos, 'REFERENCES'); y_pos -= 15;\n",
        "        for ref in references[:2]: # Limit to first 2 references\n",
        "            ref_phone = ref.get('phone', ''); ref_email = ref.get('email', '');\n",
        "            if 'contact' in ref and isinstance(ref['contact'], dict): # Handle old 'contact' sub-dict if present\n",
        "                ref_phone = ref['contact'].get('phone', ref_phone);\n",
        "                ref_email = ref['contact'].get('email', ref_email);\n",
        "            c.setFont('Helvetica-Bold', 10); c.drawString(x_pos, y_pos, ref.get('name', '')); y_pos -= 10;\n",
        "            c.setFont('Helvetica', 10); c.drawString(x_pos, y_pos, ref.get('title', '')); y_pos -= 10;\n",
        "            if ref_phone: c.drawString(x_pos, y_pos, ref_phone); y_pos -= 10;\n",
        "            if ref_email: c.drawString(x_pos, y_pos, ref_email); y_pos -= 10;\n",
        "            y_pos -= 15;\n",
        "\n",
        "    c.save(); # Finalize PDF drawing\n",
        "    return file_buffer;\n",
        "\n",
        "\n",
        "# --- FastAPI Endpoints ---\n",
        "\n",
        "@app.post(\"/generate-cv-json\", summary=\"Parse CV text and return structured JSON\")\n",
        "async def generate_cv_json_endpoint(cv_text: str = Form(...)):\n",
        "    print(f\"Received CV text (length: {len(cv_text)})\")\n",
        "\n",
        "    if not cv_text.strip():\n",
        "        print(\"Empty CV text received\")\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"CV text cannot be empty.\"})\n",
        "\n",
        "    # Ensure model is loaded before attempting inference\n",
        "    if model is None or tokenizer is None:\n",
        "        print(\"Model or tokenizer not loaded. Attempting to load now.\")\n",
        "        try:\n",
        "            # Call the startup function explicitly if not loaded\n",
        "            await load_model()\n",
        "            if model is None or tokenizer is None: # Re-check after attempting load\n",
        "                 return JSONResponse(status_code=500, content={\"error\": \"Model failed to load. Please check server startup logs.\"})\n",
        "        except RuntimeError as e:\n",
        "            return JSONResponse(status_code=500, content={\"error\": f\"Model failed to load during request: {e}\"})\n",
        "\n",
        "\n",
        "    raw_output = \"N/A\" # Initialize raw_output for error reporting consistency\n",
        "    try:\n",
        "        print(\"Starting LLM response generation...\")\n",
        "        raw_output = generate_llm_response(cv_text) # This is the initial raw string from the LLM.\n",
        "        print(\"--- Raw Output from Local LLM ---\")\n",
        "        print(raw_output[:1000] + \"...\" if len(raw_output) > 1000 else raw_output)\n",
        "\n",
        "        print(\"Converting raw output to JSON...\")\n",
        "        # The convert_raw_output_to_json function handles all the robust extraction and repair.\n",
        "        # The result (converted_json) is the \"fixed raw_output\" as a Python dictionary.\n",
        "        converted_json = convert_raw_output_to_json(raw_output)\n",
        "\n",
        "        print(\"Flattening JSON structure...\")\n",
        "        final_json = flatten_cv_json(converted_json) # Further standardizes the structure\n",
        "\n",
        "        print(\"--- Final Processed JSON ---\")\n",
        "        print(json.dumps(final_json, indent=2)[:1000] + \"...\" if len(json.dumps(final_json, indent=2)) > 1000 else json.dumps(final_json, indent=2))\n",
        "\n",
        "        return {\"json\": final_json, \"success\": True}\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSONDecodeError after all attempts: {e}\")\n",
        "        return JSONResponse(status_code=500, content={\n",
        "            \"error\": f\"Failed to parse JSON: {e}\", # Updated message\n",
        "            \"raw_output\": raw_output[:500] + \"...\" if len(raw_output) > 500 else raw_output,\n",
        "            \"success\": False\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"General error in generate_cv_json_endpoint: {e}\")\n",
        "        traceback.print_exc() # Print full traceback for debugging\n",
        "        return JSONResponse(status_code=500, content={\n",
        "            \"error\": str(e),\n",
        "            \"raw_output\": raw_output[:500] + \"...\" if len(raw_output) > 500 else raw_output,\n",
        "            \"success\": False\n",
        "        })\n",
        "\n",
        "@app.post(\"/preview-cv-json\", summary=\"Display structured CV JSON in an HTML formatted view\")\n",
        "async def preview_cv_json_endpoint(cv_json: str = Form(...)):\n",
        "    try:\n",
        "        print(\"------\")\n",
        "        data = json.loads(cv_json)\n",
        "        html_content = f\"<!DOCTYPE html><html><head><title>CV JSON Preview</title><style>body {{ font-family: monospace; white-space: pre-wrap; }}</style></head><body><pre>{json.dumps(data, indent=4)}</pre></body></html>\"\n",
        "        return HTMLResponse(content=html_content)\n",
        "    except json.JSONDecodeError:\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"Invalid JSON format.\"})\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
        "\n",
        "@app.post(\"/generate-cv-markdown\", summary=\"Generate CV in Markdown format from text\")\n",
        "async def generate_cv_markdown_endpoint(cv_text: str = Form(...)):\n",
        "    if not cv_text.strip():\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"CV text cannot be empty.\"})\n",
        "    if model is None or tokenizer is None:\n",
        "        print(\"Model or tokenizer not loaded for Markdown generation. Attempting to load now.\")\n",
        "        try:\n",
        "            await load_model()\n",
        "            if model is None or tokenizer is None:\n",
        "                 return JSONResponse(status_code=500, content={\"error\": \"Model failed to load. Please check server startup logs.\"})\n",
        "        except RuntimeError as e:\n",
        "            return JSONResponse(status_code=500, content={\"error\": f\"Model failed to load during request: {e}\"})\n",
        "\n",
        "    raw_output = \"N/A\"\n",
        "    try:\n",
        "        raw_output = generate_llm_response(cv_text)\n",
        "        # Here, converted_json is the \"fixed raw_output\" as a Python dictionary.\n",
        "        converted_json = convert_raw_output_to_json(raw_output)\n",
        "        cv_json = flatten_cv_json(converted_json)\n",
        "        # Fix markdown newlines if they're escaped as \\\\n\n",
        "        md = f\"# {cv_json.get('name', 'CV')}\\n\\n\"\n",
        "        if cv_json.get('job_title'): md += f\"## {cv_json['job_title']}\\n\\n\"\n",
        "        if cv_json.get('contact'):\n",
        "            md += \"### Contact\\n\"\n",
        "            for k, v in cv_json['contact'].items():\n",
        "                if v: md += f\"- **{k.replace('_', ' ').title()}**: {v}\\n\"\n",
        "            md += \"\\n\"\n",
        "        if cv_json.get('profile_summary'): md += f\"### Summary\\n{cv_json['profile_summary']}\\n\\n\"\n",
        "        if cv_json.get('skills'):\n",
        "            md += \"### Skills\\n\"\n",
        "            for category in cv_json['skills']:\n",
        "                md += f\"- **{category.get('category', 'Category')}**: {', '.join(category.get('items', []))}\\n\"\n",
        "            md += \"\\n\"\n",
        "        if cv_json.get('experience'):\n",
        "            md += \"### Experience\\n\"\n",
        "            for exp in cv_json['experience']:\n",
        "                md += f\"- **{exp.get('title', '')}** at {exp.get('company', '')} ({exp.get('duration', '')})\\n\"\n",
        "                for resp in exp.get('responsibilities', []): md += f\"  - {resp}\\n\"\n",
        "            md += \"\\n\"\n",
        "        if cv_json.get('education'):\n",
        "            md += \"### Education\\n\"\n",
        "            for edu in cv_json['education']:\n",
        "                md += f\"- **{edu.get('degree', '')}** from {edu.get('institution', '')} ({edu.get('duration', '')})\\n\"\n",
        "                if edu.get('details'): md += f\"  - {edu.get('details')}\\n\"\n",
        "            md += \"\\n\"\n",
        "        return {\"markdown\": md}\n",
        "    except Exception as e:\n",
        "        print(f\"Error in Markdown generation: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
        "\n",
        "\n",
        "@app.post(\"/download-cv-pdf\", summary=\"Generate and Download CV as PDF\")\n",
        "async def download_cv_pdf_endpoint(cv_text: str = Form(...)):\n",
        "    if not cv_text.strip():\n",
        "        return JSONResponse(status_code=400, content={\"error\": \"CV text cannot be empty.\"})\n",
        "    if model is None or tokenizer is None:\n",
        "        print(\"Model or tokenizer not loaded for PDF generation. Attempting to load now.\")\n",
        "        try:\n",
        "            await load_model()\n",
        "            if model is None or tokenizer is None:\n",
        "                 return JSONResponse(status_code=500, content={\"error\": \"Model failed to load. Please check server startup logs.\"})\n",
        "        except RuntimeError as e:\n",
        "            return JSONResponse(status_code=500, content={\"error\": f\"Model failed to load during request: {e}\"})\n",
        "\n",
        "    raw_output = \"N/A\"\n",
        "    try:\n",
        "        raw_output = generate_llm_response(cv_text)\n",
        "        # Here, converted_json is the \"fixed raw_output\" as a Python dictionary.\n",
        "        converted_json = convert_raw_output_to_json(raw_output)\n",
        "        cv_json = flatten_cv_json(converted_json)\n",
        "        pdf_buffer = io.BytesIO()\n",
        "        create_styled_cv_from_json(cv_json, pdf_buffer)\n",
        "        pdf_buffer.seek(0)\n",
        "        name = cv_json.get(\"name\", \"cv\").replace(\" \", \"_\")\n",
        "        filename = f\"{name}_CV.pdf\"\n",
        "        return StreamingResponse(\n",
        "            pdf_buffer,\n",
        "            media_type=\"application/pdf\",\n",
        "            headers={\"Content-Disposition\": f\"attachment; filename={filename}\"}\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error in PDF generation: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})\n",
        "\n",
        "@app.post(\"/test-raw-conversion\", summary=\"Test raw output conversion and CV generation (for debugging)\")\n",
        "async def test_raw_conversion_endpoint(raw_text: str = Form(...)):\n",
        "    \"\"\"\n",
        "    Test endpoint to convert raw LLM output to JSON, then generate Markdown and PDF.\n",
        "    Useful for debugging the full pipeline from raw output to CV.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"=== Testing Raw Output Conversion and CV Generation ===\")\n",
        "        # 1. Convert raw output to valid JSON\n",
        "        converted_json = convert_raw_output_to_json(raw_text)\n",
        "        flattened_json = flatten_cv_json(converted_json)\n",
        "\n",
        "        # 2. Generate Markdown from the flattened JSON\n",
        "        md = f\"# {flattened_json.get('name', 'CV')}\\n\\n\"\n",
        "        if flattened_json.get('job_title'): md += f\"## {flattened_json['job_title']}\\n\\n\"\n",
        "        if flattened_json.get('contact'):\n",
        "            md += \"### Contact\\n\"\n",
        "            for k, v in flattened_json['contact'].items():\n",
        "                if v: md += f\"- **{k.replace('_', ' ').title()}**: {v}\\n\"\n",
        "            md += \"\\n\"\n",
        "        if flattened_json.get('profile_summary'): md += f\"### Summary\\n{flattened_json['profile_summary']}\\n\\n\"\n",
        "        if flattened_json.get('skills'):\n",
        "            md += \"### Skills\\n\"\n",
        "            for category in flattened_json['skills']:\n",
        "                md += f\"- **{category.get('category', 'Category')}**: {', '.join(category.get('items', []))}\\n\"\n",
        "            md += \"\\n\"\n",
        "        if flattened_json.get('experience'):\n",
        "            md += \"### Experience\\n\"\n",
        "            for exp in flattened_json['experience']:\n",
        "                md += f\"- **{exp.get('title', '')}** at {exp.get('company', '')} ({exp.get('duration', '')})\\n\"\n",
        "                for resp in exp.get('responsibilities', []): md += f\"  - {resp}\\n\"\n",
        "            md += \"\\n\"\n",
        "        if flattened_json.get('education'):\n",
        "            md += \"### Education\\n\"\n",
        "            for edu in flattened_json['education']:\n",
        "                md += f\"- **{edu.get('degree', '')}** from {edu.get('institution', '')} ({edu.get('duration', '')})\\n\"\n",
        "                if edu.get('details'): md += f\"  - {edu.get('details')}\\n\"\n",
        "            md += \"\\n\"\n",
        "        # Add other sections if desired (projects, volunteering, references)\n",
        "        if flattened_json.get('projects'):\n",
        "            md += \"### Projects\\n\"\n",
        "            for proj in flattened_json['projects']:\n",
        "                md += f\"- **{proj.get('name', '')}** ({proj.get('role', '')})\\n\"\n",
        "                if proj.get('description'): md += f\"  - {proj.get('description')}\\n\"\n",
        "                if proj.get('technologies'): md += f\"  - Technologies: {', '.join(proj.get('technologies', []))}\\n\"\n",
        "            md += \"\\n\"\n",
        "        if flattened_json.get('volunteering_and_leadership'):\n",
        "            md += \"### Volunteering & Leadership\\n\"\n",
        "            for vol in flattened_json['volunteering_and_leadership']: md += f\"- {vol}\\n\"\n",
        "            md += \"\\n\"\n",
        "        if flattened_json.get('references'):\n",
        "            md += \"### References\\n\"\n",
        "            for ref in flattened_json['references']:\n",
        "                md += f\"- {ref.get('name', '')}, {ref.get('title', '')}\\n\"\n",
        "                if ref.get('phone'): md += f\"  - Phone: {ref.get('phone')}\\n\"\n",
        "                if ref.get('email'): md += f\"  - Email: {ref.get('email')}\\n\"\n",
        "            md += \"\\n\"\n",
        "\n",
        "        # 3. Generate PDF from the flattened JSON\n",
        "        pdf_buffer = io.BytesIO()\n",
        "        create_styled_cv_from_json(flattened_json, pdf_buffer)\n",
        "        pdf_buffer.seek(0)\n",
        "        pdf_base64 = base64.b64encode(pdf_buffer.getvalue()).decode('utf-8')\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"original_raw_input\": raw_text[:500] + \"...\" if len(raw_text) > 500 else raw_text,\n",
        "            \"converted_json_object\": converted_json,\n",
        "            \"flattened_json_object\": flattened_json,\n",
        "            \"generated_markdown\": md,\n",
        "            \"generated_pdf_base64\": pdf_base64,\n",
        "            \"pdf_filename\": f\"{flattened_json.get('name', 'cv').replace(' ', '_')}_RawTest.pdf\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        traceback.print_exc()\n",
        "        return JSONResponse(status_code=500, content={\n",
        "            \"success\": False,\n",
        "            \"error\": str(e),\n",
        "            \"original_raw_input\": raw_text[:500] + \"...\" if len(raw_text) > 500 else raw_text\n",
        "        })\n",
        "\n",
        "@app.get(\"/health\", summary=\"Health Check\")\n",
        "async def health_check_endpoint():\n",
        "    \"\"\"Check if the API and model are ready\"\"\"\n",
        "    return {\n",
        "        \"status\": \"healthy\",\n",
        "        \"model_loaded\": model is not None,\n",
        "        \"tokenizer_loaded\": tokenizer is not None,\n",
        "        \"groq_client_available\": False, # Always False now that Groq is removed\n",
        "        \"model_path\": MODEL_PATH\n",
        "    }\n",
        "\n",
        "@app.get(\"/\", summary=\"API Root\")\n",
        "async def read_root_endpoint():\n",
        "    return {\"message\": \"Welcome to the ATS-Friendly CV Generator API! Use /docs for API documentation.\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pctMwb59Srh",
        "outputId": "ddcb8ee2-b157-4819-da45-fb479cd0d487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting FastAPI app with Uvicorn on 0.0.0.0:8000 in a background process...\n",
            "Attempting to clear port 8000 using fuser...\n",
            "Port 8000 cleanup process completed.\n",
            "Waiting for FastAPI server to start and model to load (this may take 60-180 seconds depending on model size and GPU)...\n",
            "Attempt 1/18: Checking local server health at http://localhost:8000/health...\n",
            "Local server not yet reachable or timed out. Waiting...\n",
            "[UVICORN ERR] INFO:     Started server process [16386]\n",
            "[UVICORN ERR] INFO:     Waiting for application startup.\n",
            "[UVICORN ERR] 2025-07-29 16:58:09.225114: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "[UVICORN ERR] 2025-07-29 16:58:09.242696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "[UVICORN ERR] WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "[UVICORN ERR] E0000 00:00:1753808289.263847   16386 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "[UVICORN ERR] E0000 00:00:1753808289.270199   16386 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[UVICORN ERR] 2025-07-29 16:58:09.290849: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "[UVICORN ERR] To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Attempt 2/18: Checking local server health at http://localhost:8000/health...\n",
            "Local server not yet reachable or timed out. Waiting...\n",
            "[UVICORN OUT] Attempting to load model from: /content/drive/MyDrive/llm-cv-parser-v2/final_merged_model_v2\n",
            "[UVICORN ERR] \n",
            "[UVICORN ERR] Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]\n",
            "[UVICORN ERR] Loading checkpoint shards:  33%|███▎      | 1/3 [00:03<00:06,  3.32s/it]\n",
            "Attempt 3/18: Checking local server health at http://localhost:8000/health...\n",
            "Local server not yet reachable or timed out. Waiting...\n",
            "[UVICORN ERR] Loading checkpoint shards:  67%|██████▋   | 2/3 [00:06<00:03,  3.33s/it]\n",
            "[UVICORN ERR] Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.25s/it]\n",
            "[UVICORN ERR] Loading checkpoint shards: 100%|██████████| 3/3 [00:09<00:00,  3.27s/it]\n",
            "[UVICORN ERR] INFO:     Application startup complete.\n",
            "[UVICORN ERR] INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "Attempt 4/18: Checking local server health at http://localhost:8000/health...\n",
            "FastAPI server is up and model is loaded. Proceeding with Ngrok.\n",
            "Ngrok tunnel to port 8000 successfully opened.\n",
            "\n",
            "FastAPI app is publicly accessible at: https://f4b626e1610f.ngrok-free.app\n",
            "\n",
            "--- Important for Frontend ---\n",
            "Use this URL in your local frontend's API calls:\n",
            ">>> https://f4b626e1610f.ngrok-free.app <<<\n",
            "Your FastAPI app is running! Click here for API Docs: https://f4b626e1610f.ngrok-free.app/docs\n",
            "Stored 'public_url' (str)\n",
            "\n",
            "FastAPI server started in the background. This cell has completed execution.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import threading\n",
        "import requests\n",
        "import psutil # Import psutil to manage processes\n",
        "import signal # For more direct signal handling\n",
        "import json # Import json for health check parsing\n",
        "\n",
        "print(\"Starting FastAPI app with Uvicorn on 0.0.0.0:8000 in a background process...\")\n",
        "\n",
        "# --- Port Cleanup: Kill any existing processes on port 8000 ---\n",
        "PORT = 8000\n",
        "print(f\"Attempting to clear port {PORT} using fuser...\")\n",
        "# Use fuser to forcefully kill any process using the port. The '-k' option sends a SIGKILL signal.\n",
        "# The '-n tcp' specifies the TCP namespace.\n",
        "subprocess.run(f\"fuser -k -n tcp {PORT}\", shell=True, check=False)\n",
        "time.sleep(2) # Give the OS a moment to release the port\n",
        "print(f\"Port {PORT} cleanup process completed.\")\n",
        "# --- End Port Cleanup ---\n",
        "\n",
        "\n",
        "# Retrieve the Groq API key directly from the Colab environment's os.environ\n",
        "groq_api_key_for_subprocess = os.environ.get(\"GROQ_API_KEY\")\n",
        "if not groq_api_key_for_subprocess:\n",
        "    raise ValueError(\"GROQ_API_KEY is not set in the current Colab environment. Please ensure the cell that sets it from secrets ran correctly.\")\n",
        "\n",
        "# Create a new environment dictionary for the subprocess, inheriting current env vars\n",
        "subprocess_env = os.environ.copy()\n",
        "subprocess_env[\"GROQ_API_KEY\"] = groq_api_key_for_subprocess\n",
        "\n",
        "# Define a global variable to store the process object for easier termination later\n",
        "global uvicorn_process\n",
        "uvicorn_process = None\n",
        "\n",
        "# We use a Queue to collect output from the Uvicorn process immediately\n",
        "from queue import Queue, Empty\n",
        "uvicorn_output_queue = Queue()\n",
        "\n",
        "try:\n",
        "    # Set --log-level to 'debug' for maximum verbosity\n",
        "    uvicorn_process = subprocess.Popen(\n",
        "        [\"uvicorn\", \"cv_api:app\", \"--host\", \"0.0.0.0\", \"--port\", str(PORT), \"--log-level\", \"debug\"],\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.PIPE,\n",
        "        text=True,\n",
        "        bufsize=1, # Line-buffered\n",
        "        universal_newlines=True,\n",
        "        env=subprocess_env,\n",
        "        preexec_fn=os.setsid # For more robust process handling\n",
        "    )\n",
        "\n",
        "    # Function to continuously read and put Uvicorn output into a Queue\n",
        "    def enqueue_output(out_stream, queue, prefix):\n",
        "        for line in iter(out_stream.readline, ''):\n",
        "            queue.put(f\"{prefix} {line.strip()}\")\n",
        "        out_stream.close()\n",
        "\n",
        "    # Start separate threads to capture stdout and stderr\n",
        "    stdout_thread = threading.Thread(target=enqueue_output, args=(uvicorn_process.stdout, uvicorn_output_queue, \"[UVICORN OUT]\"))\n",
        "    stderr_thread = threading.Thread(target=enqueue_output, args=(uvicorn_process.stderr, uvicorn_output_queue, \"[UVICORN ERR]\"))\n",
        "\n",
        "    stdout_thread.daemon = True\n",
        "    stderr_thread.daemon = True\n",
        "\n",
        "    stdout_thread.start()\n",
        "    stderr_thread.start()\n",
        "\n",
        "    print(\"Waiting for FastAPI server to start and model to load (this may take 60-180 seconds depending on model size and GPU)...\")\n",
        "\n",
        "    # Health check loop\n",
        "    local_health_url = f\"http://localhost:{PORT}/health\"\n",
        "    max_retries = 18 # Up to 3 minutes\n",
        "    retry_delay = 10 # seconds\n",
        "\n",
        "    server_ready = False\n",
        "    for i in range(max_retries):\n",
        "        # Print any collected Uvicorn output during the wait\n",
        "        while not uvicorn_output_queue.empty():\n",
        "            try:\n",
        "                print(uvicorn_output_queue.get_nowait())\n",
        "            except Empty:\n",
        "                break # Queue is empty\n",
        "\n",
        "        # Check if the Uvicorn process itself has crashed\n",
        "        poll_result = uvicorn_process.poll()\n",
        "        if poll_result is not None:\n",
        "            print(f\"\\nUvicorn process terminated unexpectedly with exit code {poll_result}.\")\n",
        "            print(\"--- Captured Uvicorn Output (before crash) ---\")\n",
        "            while not uvicorn_output_queue.empty():\n",
        "                try:\n",
        "                    print(uvicorn_output_queue.get_nowait())\n",
        "                except Empty:\n",
        "                    break\n",
        "            print(\"---------------------------------------------\")\n",
        "            raise SystemExit(\"Uvicorn process crashed during startup.\")\n",
        "\n",
        "        # Attempt HTTP health check\n",
        "        try:\n",
        "            print(f\"Attempt {i+1}/{max_retries}: Checking local server health at {local_health_url}...\")\n",
        "            health_response = requests.get(local_health_url, timeout=5)\n",
        "            if health_response.status_code == 200 and health_response.json().get('model_loaded'):\n",
        "                print(\"FastAPI server is up and model is loaded. Proceeding with Ngrok.\")\n",
        "                server_ready = True\n",
        "                break\n",
        "            elif health_response.status_code == 200:\n",
        "                print(\"FastAPI server is up, but model is still loading. Waiting...\")\n",
        "            else:\n",
        "                print(f\"Local server returned status {health_response.status_code} for health check. Waiting...\")\n",
        "        except (requests.exceptions.ConnectionError, requests.exceptions.Timeout):\n",
        "            print(\"Local server not yet reachable or timed out. Waiting...\")\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Local server responded, but not with valid JSON for health check. Waiting...\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred during health check: {e}. Waiting...\")\n",
        "\n",
        "        time.sleep(retry_delay)\n",
        "\n",
        "    if not server_ready:\n",
        "        print(\"\\nError: FastAPI server did not become ready within the allotted time.\")\n",
        "        print(\"--- Final Captured Uvicorn Output ---\")\n",
        "        while not uvicorn_output_queue.empty():\n",
        "            try:\n",
        "                print(uvicorn_output_queue.get_nowait())\n",
        "            except Empty:\n",
        "                break\n",
        "        print(\"-------------------------------------\")\n",
        "        raise SystemExit(\"FastAPI server failed to start.\")\n",
        "\n",
        "    # --- Ngrok Setup (only if server is ready) ---\n",
        "    public_url = None\n",
        "    ngrok.set_auth_token(os.environ.get(\"NGROK_AUTH_TOKEN\"))\n",
        "    http_tunnel = ngrok.connect(PORT, bind_tls=True)\n",
        "    public_url = http_tunnel.public_url\n",
        "    print(f\"Ngrok tunnel to port {PORT} successfully opened.\")\n",
        "    print(f\"\\nFastAPI app is publicly accessible at: {public_url}\")\n",
        "    print(\"\\n--- Important for Frontend ---\")\n",
        "    print(f\"Use this URL in your local frontend's API calls:\\n>>> {public_url} <<<\")\n",
        "    print(f\"Your FastAPI app is running! Click here for API Docs: {public_url}/docs\")\n",
        "\n",
        "    get_ipython().run_line_magic('store', 'public_url')\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during FastAPI startup or Ngrok tunnel setup: {e}\")\n",
        "    # Ensure all collected output is printed on error\n",
        "    print(\"--- Remaining Uvicorn Output on Error ---\")\n",
        "    while not uvicorn_output_queue.empty():\n",
        "        try:\n",
        "            print(uvicorn_output_queue.get_nowait())\n",
        "        except Empty:\n",
        "            break\n",
        "    print(\"--------------------------------------\")\n",
        "\n",
        "    # Attempt to terminate Uvicorn process if it's still running\n",
        "    if uvicorn_process and uvicorn_process.poll() is None:\n",
        "        print(\"Attempting to terminate Uvicorn process...\")\n",
        "        try:\n",
        "            os.killpg(os.getpgid(uvicorn_process.pid), signal.SIGTERM)\n",
        "            uvicorn_process.wait(timeout=10)\n",
        "            if uvicorn_process.poll() is None: # Still running after SIGTERM\n",
        "                os.killpg(os.getpgid(uvicorn_process.pid), signal.SIGKILL) # Force kill\n",
        "                uvicorn_process.wait(timeout=10)\n",
        "            print(\"Uvicorn process terminated.\")\n",
        "        except Exception as kill_e:\n",
        "            print(f\"Error terminating Uvicorn process: {kill_e}\")\n",
        "    elif uvicorn_process:\n",
        "        print(f\"Uvicorn process already terminated with exit code: {uvicorn_process.poll()}\")\n",
        "    raise SystemExit(\"FastAPI server or ngrok tunnel failed to start. Exiting.\")\n",
        "\n",
        "print(\"\\nFastAPI server started in the background. This cell has completed execution.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7GEKC4gAv7A",
        "outputId": "b33e7fd7-c566-469b-930d-371a4f855c4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved public_url from stored variable: https://f4b626e1610f.ngrok-free.app\n",
            "Testing API at: https://f4b626e1610f.ngrok-free.app\n",
            "\n",
            "--- Testing /generate-cv-json ---\n",
            "JSON response received successfully:\n",
            "{\n",
            "  \"json\": {\n",
            "    \"name\": \"Dulaj Upananda\",\n",
            "    \"contact\": {\n",
            "      \"phone\": \"+94 76 832 3678\",\n",
            "      \"email\": \"dulajupananda@gmail.com\"\n",
            "    },\n",
            "    \"profile_summary\": \"I'm Dulaj Upananda, a SOFTWARE ENGINEER from Colombo, Sri Lanka. Contact me at (+94) 76 832 3678 or dulajupananda@gmail.com. I am a responsible, self-motivated, skillful, and dedicated undergraduate with real spirit and leadership qualities, who is willing to accept challenges. Seeking an opportunity as a Software Engineer to apply and explore existing and forthcoming technologies in the field of information technology.\",\n",
            "    \"skills\": [\n",
            "      {\n",
            "        \"category\": \"Programming Languages\",\n",
            "        \"items\": [\n",
            "          \"Java\",\n",
            "          \"Python\",\n",
            "          \"C\",\n",
            "          \"JavaScript\",\n",
            "          \"GoLang\",\n",
            "          \"Dart\",\n",
            "          \"TypeScript\"\n",
            "        ]\n",
            "      },\n",
            "      {\n",
            "        \"category\": \"Frontend\",\n",
            "        \"items\": [\n",
            "          \"ReactJs\",\n",
            "          \"HTML5\",\n",
            "          \"CSS3\",\n",
            "          \"ReactNative\",\n",
            "          \"Tailwind ...\n",
            "\n",
            "--- Testing /generate-cv-markdown ---\n",
            "Markdown response received successfully:\n",
            "# Dulaj Upananda\n",
            "\n",
            "### Contact\n",
            "- **Phone**: +94 76 832 3678\n",
            "- **Email**: dulajupananda@gmail.com\n",
            "\n",
            "### Summary\n",
            "I'm Dulaj Upananda, a SOFTWARE ENGINEER from Colombo, Sri Lanka. Contact me at (+94) 76 832 3678 or dulajupananda@gmail.com. I am a responsible, self-motivated, skillful, and dedicated undergraduate with real spirit and leadership qualities, who is willing to accept challenges. Seeking an opportunity as a Software Engineer to apply and explore existing and forthcoming technologies in the field of information technology.\n",
            "\n",
            "### Skills\n",
            "- **Programming Languages**: Java, Python, C, JavaScript, GoLang, Dart, TypeScript\n",
            "- **Frontend**: ReactJs, HTML5, CSS3, ReactNative, Tailwind CSS\n",
            "- **Backend**: ExpressJs, NodeJs, Spring Boot, Django, Flask\n",
            "- **Mobile App Development**: Flutter, ReactNative, Swift, Kotlin\n",
            "- **DevOps**: Docker, Git, Jira, Azure\n",
            "- **Design**: Figma, Adobe XD, Blender\n",
            "\n",
            "### Experience\n",
            "- **Intern Software Engineer** at FutureCX Lanka (Pvt) Ltd (February 2024 - August 2024...\n",
            "\n",
            "--- Testing /download-cv-pdf ---\n",
            "PDF downloaded successfully as 'generated_cv.pdf'\n",
            "You can download this file from the Colab file browser (left sidebar -> folder icon).\n",
            "\n",
            "--- Testing /test-raw-conversion with corrupted JSON ---\n",
            "Raw conversion test successful:\n",
            "{\n",
            "  \"success\": true,\n",
            "  \"original_raw_input\": \"\\n'raw_output': '{\\\"name\\\": \\\"Jayanithya Madhushani\\\", \\\"contact\\\": {\\\"phone\\\": \\\"+94 76 560 7953\\\", \\\"email\\\": \\\"jayanithyamadhushani@icloud.com\\\"}, \\\"profile_summary\\\": \\\"I am Jayanithya Madhushani, an aspiring Quality Assurance Engineer based in Anuradhapura, Sri Lanka. You can reach me at (+94) 76 560 7953 or via email at jayanithyamadhushani@icloud.com. You can also find my professional work on GitHub, LinkedIn, and Medium.\\\", \\\"experience\\\": [{\\\"title\\\": \\\"Associate Software Engineer\\\", \\\"company\\\": \\\"X-ONT Software ...\",\n",
            "  \"converted_json_object\": {\n",
            "    \"name\": \"Jayanithya Madhushani\",\n",
            "    \"contact\": {\n",
            "      \"phone\": \"+94 76 560 7953\",\n",
            "      \"email\": \"jayanithyamadhushani@icloud.com\"\n",
            "    },\n",
            "    \"profile_summary\": \"I am Jayanithya Madhushani, an aspiring Quality Assurance Engineer based in Anuradhapura, Sri Lanka. You can reach me at (+94) 76 560 7953 or via email at jayanithyamadhushani@icloud.com. You can also find my professional work on GitHub, LinkedIn, and Medium.\",\n",
            "    \"experience\": [\n",
            "      {\n",
            "        \"title\": \"Associate Software Engineer\",\n",
            "        \"company\": \"X-ONT Software (Pvt) Ltd.\",\n",
            "        \"duration\": \"July 2022 - September 2022\",\n",
            "        \"responsibilities\": [\n",
            "          \"Enhanced core product components using ASP.NET and Angular.\",\n",
            "          \"Developed new features, refactored code, improved system performance, and redesigned UI workflows to boost user experience.\",\n",
            "          \"Managed MS SQL Server databases and created business intelligence reports using Crystal Reports while collaborating with cross-functional teams to resolve technical issues and reduce downtime.\"\n",
            "        ],\n",
            "        \"project\": [\n",
            "          {\n",
            "            \"name\": \"MERN Job Portal\",\n",
            "            \"role\": \"Developer\",\n",
            "            \"description\": \"Built a job search platform that allows employers to post jobs and users to manage their accounts with Firebase authentication.\",\n",
            "            \"technologies\": [\n",
            "              \"React\",\n",
            "              \"TailwindCSS\",\n",
            "              \"Node.js\",\n",
            "              \"Express.js\",\n",
            "              \"MongoDB\"\n",
            "            ]\n",
            "          },\n",
            "          {\n",
            "            \"name\": \"EveM Event Management Software\",\n",
            "            \"role\": \"UI Designer, Frontend and Backend Developer, and API Integrator\",\n",
            "            \"description\": \"Developed the EveM Event Management Software, which automates event planning and coordination by replacing traditional Excel-based workflows.\",\n",
            "            \"technologies\": [\n",
            "              \"ReactJS\",\n",
            "              \"ASP.NET\",\n",
            "              \"MS SQL\"\n",
            "            ]\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    ],\n",
            "    \"education\": [\n",
            "      {\n",
            "        \"degree\": \"Bachelor of Science Honours in Information Technology and Management\",\n",
            "        \"institution\": \"University of Moratuwa\",\n",
            "        \"duration\": \"2016 - 2023\",\n",
            "        \"details\": \"CGPA: 3.21\"\n",
            "      }\n",
            "    ],\n",
            "    \"volunteering_and_leadership\": [\n",
            "      \"Designer at SEDS Mora and UoM INTECS\",\n",
            "      \"Video Editor at the Rotaract Club of University of Moratuwa\",\n",
            "      \"Graphic & Video Designer at Visual Room\"\n",
            "    ],\n",
            "    \"references\": [\n",
            "      {\n",
            "        \"name\": \"Mr. B.H. Sudantha\",\n",
            "        \"title\": \"Dean of the Faculty of Information Technology\",\n",
            "        \"phone\": \"+94 71 572 1744\",\n",
            "        \"email\": \"sudanthabh@uom.lk\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Mr. Kumudu Rajapakshe\",\n",
            "        \"title\": \"Chief Financial Officer at Senkadagala Finance PLC\",\n",
            "        \"phone\": \"+94 77 307 9199\",\n",
            "        \"email\": \"kumudu@senfin.com\"\n",
            "      }\n",
            "    ],\n",
            "    \"job_title\": \"\",\n",
            "    \"skills\": [],\n",
            "    \"projects\": []\n",
            "  },\n",
            "  \"flattened_json_object\": {\n",
            "    \"name\": \"Jayanithya Madhushani\",\n",
            "    \"contact\": {\n",
            "      \"phone\": \"+94 76 560 7953\",\n",
            "      \"email\": \"jayanithyamadhushani@icloud.com\"\n",
            "    },\n",
            "    \"profile_summary\": \"I am Jayanithya Madhushani, an aspiring Quality Assurance Engineer based in Anuradhapura, Sri Lanka. You can reach me at (+94) 76 560 7953 or via email at jayanithyamadhushani@icloud.com. You can also find my professional work on GitHub, LinkedIn, and Medium.\",\n",
            "    \"experience\": [\n",
            "      {\n",
            "        \"title\": \"Associate Software Engineer\",\n",
            "        \"company\": \"X-ONT Software (Pvt) Ltd.\",\n",
            "        \"duration\": \"July 2022 - September 2022\",\n",
            "        \"responsibilities\": [\n",
            "          \"Enhanced core product components using ASP.NET and Angular.\",\n",
            "          \"Developed new features, refactored code, improved system performance, and redesigned UI workflows to boost user experience.\",\n",
            "          \"Managed MS SQL Server databases and created business intelligence reports using Crystal Reports while collaborating with cross-functional teams to resolve technical issues and reduce downtime.\"\n",
            "        ],\n",
            "        \"project\": [\n",
            "          {\n",
            "            \"name\": \"MERN Job Portal\",\n",
            "            \"role\": \"Developer\",\n",
            "            \"description\": \"Built a job search platform that allows employers to post jobs and users to manage their accounts with Firebase authentication.\",\n",
            "            \"technologies\": [\n",
            "              \"React\",\n",
            "              \"TailwindCSS\",\n",
            "              \"Node.js\",\n",
            "              \"Express.js\",\n",
            "              \"MongoDB\"\n",
            "            ]\n",
            "          },\n",
            "          {\n",
            "            \"name\": \"EveM Event Management Software\",\n",
            "            \"role\": \"UI Designer, Frontend and Backend Developer, and API Integrator\",\n",
            "            \"description\": \"Developed the EveM Event Management Software, which automates event planning and coordination by replacing traditional Excel-based workflows.\",\n",
            "            \"technologies\": [\n",
            "              \"ReactJS\",\n",
            "              \"ASP.NET\",\n",
            "              \"MS SQL\"\n",
            "            ]\n",
            "          }\n",
            "        ]\n",
            "      }\n",
            "    ],\n",
            "    \"education\": [\n",
            "      {\n",
            "        \"degree\": \"Bachelor of Science Honours in Information Technology and Management\",\n",
            "        \"institution\": \"University of Moratuwa\",\n",
            "        \"duration\": \"2016 - 2023\",\n",
            "        \"details\": \"CGPA: 3.21\"\n",
            "      }\n",
            "    ],\n",
            "    \"volunteering_and_leadership\": [\n",
            "      \"Designer at SEDS Mora and UoM INTECS\",\n",
            "      \"Video Editor at the Rotaract Club of University of Moratuwa\",\n",
            "      \"Graphic & Video Designer at Visual Room\"\n",
            "    ],\n",
            "    \"references\": [\n",
            "      {\n",
            "        \"name\": \"Mr. B.H. Sudantha\",\n",
            "        \"title\": \"Dean of the Faculty of Information Technology\",\n",
            "        \"phone\": \"+94 71 572 1744\",\n",
            "        \"email\": \"sudanthabh@uom.lk\"\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"Mr. Kumudu Rajapakshe\",\n",
            "        \"title\": \"Chief Financial Officer at Senkadagala Finance PLC\",\n",
            "        \"phone\": \"+94 77 307 9199\",\n",
            "        \"email\": \"kumudu@senfin.com\"\n",
            "      }\n",
            "    ],\n",
            "    \"job_title\": \"\",\n",
            "    \"skills\": [],\n",
            "    \"projects\": []\n",
            "  },\n",
            "  \"generated_markdown\": \"# Jayanithya Madhushani\\n\\n### Contact\\n- **Phone**: +94 76 560 7953\\n- **Email**: jayanithyamadhushani@icloud.com\\n\\n### Summary\\nI am Jayanithya Madhushani, an aspiring Quality Assurance Engineer based in Anuradhapura, Sri Lanka. You can reach me at (+94) 76 560 7953 or via email at jayanithyamadhushani@icloud.com. You can also find my professional work on GitHub, LinkedIn, and Medium.\\n\\n### Experience\\n- **Associate Software Engineer** at X-ONT Software (Pvt) Ltd. (July 2022 - September 2022)\\n  - Enhanced core product components using ASP.NET and Angular.\\n  - Developed new features, refactored code, improved system performance, and redesigned UI workflows to boost user experience.\\n  - Managed MS SQL Server databases and created business intelligence reports using Crystal Reports while collaborating with cross-functional teams to resolve technical issues and reduce downtime.\\n\\n### Education\\n- **Bachelor of Science Honours in Information Technology and Management** from University of Moratuwa (2016 - 2023)\\n  - CGPA: 3.21\\n\\n### Volunteering & Leadership\\n- Designer at SEDS Mora and UoM INTECS\\n- Video Editor at the Rotaract Club of University of Moratuwa\\n- Graphic & Video Designer at Visual Room\\n\\n### References\\n- Mr. B.H. Sudantha, Dean of the Faculty of Information Technology\\n  - Phone: +94 71 572 1744\\n  - Email: sudanthabh@uom.lk\\n- Mr. Kumudu Rajapakshe, Chief Financial Officer at Senkadagala Finance PLC\\n  - Phone: +94 77 307 9199\\n  - Email: kumudu@senfin.com\\n\\n\",\n",
            "  \"generated_pdf_base64\": \"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\",\n",
            "  \"pdf_filename\": \"Jayanithya_Madhushani_RawTest.pdf\"\n",
            "}\n",
            "\n",
            "--- All API tests completed ---\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- IMPORTANT: Retrieve the public_url from the previous cell's output ---\n",
        "# This line attempts to retrieve the stored public_url.\n",
        "try:\n",
        "    get_ipython().run_line_magic('store', '-r public_url')\n",
        "    print(f\"Retrieved public_url from stored variable: {public_url}\")\n",
        "except Exception:\n",
        "    print(\"Could not retrieve public_url from stored variable. Please ensure the previous cell ran successfully.\")\n",
        "    # Fallback to manual entry if %store failed (uncomment and replace if needed)\n",
        "    # public_url = \"https://your_ngrok_url_here.ngrok-free.app\"\n",
        "\n",
        "\n",
        "if not public_url or \"YOUR_NGROK_PUBLIC_URL_HERE\" in public_url:\n",
        "    raise ValueError(\"Public URL is not set. Please set it manually or ensure the previous cell ran correctly and stored the URL.\")\n",
        "\n",
        "print(f\"Testing API at: {public_url}\")\n",
        "\n",
        "# Sample CV text for testing\n",
        "sample_cv_text = \"\"\"\n",
        "I'm Dulaj Upananda, a SOFTWARE ENGINEER from Colombo, Sri Lanka. Contact me at (+94) 76 832 3678 or dulajupananda@gmail.com. I am a responsible, self-motivated, skillful, and dedicated undergraduate with real spirit and leadership qualities, who is willing to accept challenges. Seeking an opportunity as a Software Engineer to apply and explore existing and forthcoming technologies in the field of information technology.\n",
        "\n",
        "My technical skills encompass a wide range of programming languages including Java, Python, C, JavaScript, GoLang, Dart, and TypeScript. I am proficient in various frameworks such as ReactJs, NodeJs, NextJs, Angular, ExpressJs, Flutter, and React Native. My database expertise includes MySQL, MongoDB, MS SQL, and PostgreSQL. I work comfortably with development environments like VS Code, CLion, Visual Studio, IntelliJ IDEA, and NetBeans. Additionally, I have experience with essential development tools including Git for version control, Jira for project management, Docker for containerization, Figma for design, Github for code collaboration, and Blender for 3D modeling.\n",
        "\n",
        "From February 2024 to August 2024, I served as an Intern Software Engineer at FutureCX Lanka (Pvt) Ltd where I made significant contributions to the company's core products. During my internship, I enhanced and maintained core product components using Flutter and GoLang technologies, developed new features and optimized performance to improve user experience, managed PostgreSQL databases effectively, collaborated with teams to troubleshoot and resolve technical issues, and delivered efficient solutions under tight deadlines consistently.\n",
        "\n",
        "Throughout my academic and professional journey, I have completed several notable projects that demonstrate my full-stack development capabilities. The Highway Bus Management System was a comprehensive Level 02 Software Project where I served as a Full-Stack Developer, building an integrated system consisting of a mobile app offering bookings and live bus tracking functionality, along with a web app featuring admin functionalities. My contribution included UI design, frontend development, API integration, backend development, and database design using technologies including ReactJS, ExpressJS, MongoDB, Firebase, ReactNative, and Figma. The EduApp E-learning platform was another significant project where I developed a mobile app featuring secure authentication, course management, and user management capabilities, with Admins handling student approvals and Super Admins overseeing the entire system using Flutter, GoLang, and PostgreSQL technologies. I also created a MERN Job Portal as a Full-Stack Developer, building a job search platform with employer posting capabilities and Firebase authentication for secure user management, utilizing ReactJS, Firebase, ExpressJS, MongoDB, and Tailwind CSS. Currently, I am working on an Event Management and Ticketing System as a Full-Stack Developer, creating an event management and ticket booking app for attendees and event organizers with features including event management, event search, and ticket purchasing using ReactJS, Tailwind CSS, Firebase, GoLang, PostgreSQL, and Docker. Another ongoing project is the Salon Appointment Reservation Mobile App where I serve as a Full-Stack Developer, building a salon appointment management app for users and salon owners with features to search nearby salons, make reservations, and manage reservations using Flutter, Firebase, GoLang, and MongoDB. I am also developing an AI IT Path Finder, which is an AI-Driven Career Guidance Platform for IT Professionals featuring personalized job recommendations, automated dynamic CV generation, an application tracking system, and intelligent interview preparation using Django, ReactJS, Spacy, PostgreSQL, MongoDB, DraftJS, and Puppeteer technologies.\n",
        "\n",
        "My educational background includes pursuing a Bachelor of Science Honors in Information Technology & Management at the University of Moratuwa, Sri Lanka from 2021 to 2025, where I have maintained a CGPA of 3.20 and completed my Final Year Research Project. Prior to my university studies, I completed a Diploma in Software Engineering at ESOFT Metro Campus from 2020 to 2021, which provided me with foundational programming and development skills. I also obtained dual diplomas from SIBA Campus between August 2019 and March 2020, earning both a Diploma in Information Technology and a Diploma in English, which enhanced my technical knowledge and communication skills. My secondary education was completed at Kingswood College, Kandy, where I achieved excellent results in my GCE Advanced Level examinations in 2019 in the Biological Science Stream with grades AAB, and earlier completed my GCE Ordinary Level examinations in 2014 with outstanding performance achieving 7 A grades, one B grade, and one C grade.\n",
        "\n",
        "My involvement in volunteering and leadership activities has been extensive and meaningful. I served as the Web and Technology Manager of SEDS Mora from 2023 to 2024, where I was responsible for maintaining the organization's digital presence and implementing technological solutions. I was an active member of Mora Spirit intra-university media network from 2022 to 2023, participating in various university cultural and social activities. I also represented my university as a member of the Baseball team from 2022 to 2023, demonstrating my commitment to sports and teamwork. Since 2020, I have been a dedicated member of the Sasnaka Sansada Foundation, contributing to community service and social welfare initiatives. During my school years at Kingswood College, I held significant leadership positions including Senior Prefect from 2016 to 2017 and Junior Prefect from 2013 to 2014, where I developed essential leadership and management skills. I also served as the Batch Representative for the Faculty of Information Technology during my second year at university, representing my fellow students in academic and administrative matters.\n",
        "\n",
        "For professional references, I can provide contact details for Mr. B.H. Sudantha, who serves as the Dean of the Faculty of Information Technology at the University of Moratuwa and can be reached at mobile number +94 71 572 1744 or via email at sudanthabh@uom.lk. Additionally, Mr. Kumudu Rajapakshe, who holds the position of Chief Financial Officer at Senkadagala Finance PLC, is available as a reference and can be contacted at mobile number +94 77 307 9199 or through email at kumudu@senfin.com.\n",
        "\"\"\"\n",
        "\n",
        "# --- Test /generate-cv-json endpoint ---\n",
        "print(\"\\n--- Testing /generate-cv-json ---\")\n",
        "json_url = f\"{public_url}/generate-cv-json\"\n",
        "try:\n",
        "    response_json = requests.post(json_url, data={'cv_text': sample_cv_text})\n",
        "    response_json.raise_for_status() # Raise an exception for HTTP errors\n",
        "    json_data = response_json.json()\n",
        "    print(\"JSON response received successfully:\")\n",
        "    print(json.dumps(json_data, indent=2)[:1000] + \"...\" if len(json.dumps(json_data, indent=2)) > 1000 else json.dumps(json_data, indent=2))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error calling /generate-cv-json: {e.response.text}\")\n",
        "    if response_json:\n",
        "        print(f\"Response status code: {response_json.status_code}\")\n",
        "        print(f\"Response text: {response_json.text}\")\n",
        "\n",
        "# --- Test /generate-cv-markdown endpoint ---\n",
        "print(\"\\n--- Testing /generate-cv-markdown ---\")\n",
        "markdown_url = f\"{public_url}/generate-cv-markdown\"\n",
        "try:\n",
        "    response_md = requests.post(markdown_url, data={'cv_text': sample_cv_text})\n",
        "    response_md.raise_for_status()\n",
        "    markdown_data = response_md.json()\n",
        "    print(\"Markdown response received successfully:\")\n",
        "    print(markdown_data.get('markdown', 'No markdown content found.')[:1000] + \"...\" if len(markdown_data.get('markdown', '')) > 1000 else markdown_data.get('markdown', 'No markdown content found.'))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error calling /generate-cv-markdown: {e}\")\n",
        "    if response_md:\n",
        "        print(f\"Response status code: {response_md.status_code}\")\n",
        "        print(f\"Response text: {response_md.text}\")\n",
        "\n",
        "# --- Test /download-cv-pdf endpoint ---\n",
        "print(\"\\n--- Testing /download-cv-pdf ---\")\n",
        "pdf_url = f\"{public_url}/download-cv-pdf\"\n",
        "try:\n",
        "    response_pdf = requests.post(pdf_url, data={'cv_text': sample_cv_text})\n",
        "    response_pdf.raise_for_status()\n",
        "\n",
        "    # Save the PDF to a file\n",
        "    pdf_filename = \"generated_cv.pdf\"\n",
        "    with open(pdf_filename, 'wb') as f:\n",
        "        f.write(response_pdf.content)\n",
        "    print(f\"PDF downloaded successfully as '{pdf_filename}'\")\n",
        "    print(f\"You can download this file from the Colab file browser (left sidebar -> folder icon).\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error calling /download-cv-pdf: {e}\")\n",
        "    if response_pdf:\n",
        "        print(f\"Response status code: {response_pdf.status_code}\")\n",
        "        print(f\"Response text: {response_pdf.text}\")\n",
        "\n",
        "# --- Test /test-raw-conversion endpoint with the provided corrupted JSON ---\n",
        "print(\"\\n--- Testing /test-raw-conversion with corrupted JSON ---\")\n",
        "corrupted_json_input = '''\n",
        "'raw_output': '{\"name\": \"Jayanithya Madhushani\", \"contact\": {\"phone\": \"+94 76 560 7953\", \"email\": \"jayanithyamadhushani@icloud.com\"}, \"profile_summary\": \"I am Jayanithya Madhushani, an aspiring Quality Assurance Engineer based in Anuradhapura, Sri Lanka. You can reach me at (+94) 76 560 7953 or via email at jayanithyamadhushani@icloud.com. You can also find my professional work on GitHub, LinkedIn, and Medium.\", \"experience\": [{\"title\": \"Associate Software Engineer\", \"company\": \"X-ONT Software (Pvt) Ltd.\", \"duration\": \"July 2022 - September 2022\", \"responsibilities\": [\"Enhanced core product components using ASP.NET and Angular.\", \"Developed new features, refactored code, improved system performance, and redesigned UI workflows to boost user experience.\", \"Managed MS SQL Server databases and created business intelligence reports using Crystal Reports while collaborating with cross-functional teams to resolve technical issues and reduce downtime.\"], \"project\": [{\"name\": \"MERN Job Portal\", \"role\": \"Developer\", \"description\": \"Built a job search platform that allows employers to post jobs and users to manage their accounts with Firebase authentication.\", \"technologies\": [\"React\", \"TailwindCSS\", \"Node.js\", \"Express.js\", \"MongoDB\"]}, {\"name\": \"EveM Event Management Software\", \"role\": \"UI Designer, Frontend and Backend Developer, and API Integrator\", \"description\": \"Developed the EveM Event Management Software, which automates event planning and coordination by replacing traditional Excel-based workflows.\", \"technologies\": [\"ReactJS\", \"ASP.NET\", \"MS SQL\"]}]}], \"education\": [{\"degree\": \"Bachelor of Science Honours in Information Technology and Management\", \"institution\": \"University of Moratuwa\", \"duration\": \"2016 - 2023\", \"details\": \"CGPA: 3.21\"}], \"volunteering_and_leadership\": [\"Designer at SEDS Mora and UoM INTECS\", \"Video Editor at the Rotaract Club of University of Moratuwa\", \"Graphic & Video Designer at Visual Room\"], \"references\": [{\"name\": \"Mr. B.H. Sudantha\", \"title\": \"Dean of the Faculty of Information Technology\", \"contact\": {\"phone\": \"+94 71 572 1744\", \"email\": \"sudanthabh@uom.lk\"}}, {\"name\": \"Mr. Kumudu Rajapakshe\", \"title\": \"Chief Financial Officer at Senkadagala Finance PLC\", \"contact\": {\"phone\": \"+94 77 307 9199\", \"email\": \"kumudu@senfin.com\"}}]}'\n",
        "'''\n",
        "\n",
        "test_raw_conversion_url = f\"{public_url}/test-raw-conversion\"\n",
        "try:\n",
        "    response_raw_conversion = requests.post(test_raw_conversion_url, data={'raw_text': corrupted_json_input})\n",
        "    response_raw_conversion.raise_for_status()\n",
        "    raw_conversion_data = response_raw_conversion.json()\n",
        "    print(\"Raw conversion test successful:\")\n",
        "    print(json.dumps(raw_conversion_data, indent=2))\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error calling /test-raw-conversion: {e}\")\n",
        "    if response_raw_conversion:\n",
        "        print(f\"Response status code: {response_raw_conversion.status_code}\")\n",
        "        print(f\"Response text: {response_raw_conversion.text}\")\n",
        "\n",
        "print(\"\\n--- All API tests completed ---\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
